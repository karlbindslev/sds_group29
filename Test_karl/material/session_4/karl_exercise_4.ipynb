{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Set 4: Data Structuring 1\n",
    "\n",
    "*Afternoon, August 14, 2018*\n",
    "\n",
    "In this Exercise Set we will apply some of the basic things we have learned with pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load modules\n",
    "We begin by loading relevant packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Exercise Section 4.1: Weather, part 1\n",
    "\n",
    "Some data sources are open and easy to collect data from. They can be 'scraped' as is and they are already in a table format. This Exercise part of exercises is the first part of three that work with weather data, the follow ups are Exercise Sections 6.1 and 7.1. Our source will be National Oceanic and Atmospheric Administration (NOAA) which have a global data collection going back a couple of centuries. This collection is called Global Historical Climatology Network (GHCN). A description of GHCN can be found [here](https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/by_year/readme.txt)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> **Ex. 4.1.1:** Use Pandas' CSV reader to fetch  daily data weather from 1864 for various stations - available [here](https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/by_year/). \n",
    "\n",
    "> *Hint 1*: for compressed files you may need to specify the keyword `compression`.\n",
    "\n",
    "> *Hint 2*: keyword `header` can be specified as the CSV has no column names.\n",
    "\n",
    "> *Hint 3*: Specify the path, as the URL linking directly to the 1864 file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0         1     2    3    4    5  6   7\n",
      "0  ITE00100550  18640101  TMAX   10  NaN  NaN  E NaN\n",
      "1  ITE00100550  18640101  TMIN  -23  NaN  NaN  E NaN\n",
      "2  ITE00100550  18640101  PRCP   25  NaN  NaN  E NaN\n",
      "3  ASN00079028  18640101  PRCP    0  NaN  NaN  a NaN\n",
      "4  USC00064757  18640101  PRCP  119  NaN  NaN  F NaN\n"
     ]
    }
   ],
   "source": [
    "# [Answer to Ex. 4.1.1]\n",
    "df = pd.read_csv('https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/by_year/1864.csv.gz', header = None)\n",
    "print(df.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> **Ex. 4.1.2:** Structure your weather DataFrame by using only the relevant columns (station identifier, data, observation type, observation value), rename them. Make sure observations are correctly formated (how many decimals should we add? one?).\n",
    "\n",
    "> *Hint:* rename can be done with `df.columns=COLS` where `COLS` is a list of column names.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Station identifier  Data  Observation value Observation type\n",
      "0        ITE00100550  TMAX                 10                E\n",
      "1        ITE00100550  TMIN                -23                E\n",
      "2        ITE00100550  PRCP                 25                E\n",
      "3        ASN00079028  PRCP                  0                a\n",
      "4        USC00064757  PRCP                119                F\n"
     ]
    }
   ],
   "source": [
    "# [Answer to Ex. 4.1.2]\n",
    "df2 = df[[0,2,3,6]]\n",
    "#print(df)\n",
    "df2.columns = ['Station identifier', 'Data', 'Observation value', 'Observation type']\n",
    "print(df2.head(5))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> **Ex. 4.1.3:**  Select data for the station `ITE00100550` and only observations for maximal temperature. Make a copy of the DataFrame. Explain in a one or two sentences how copying works.\n",
    "\n",
    "> *Hint 1*: the `&` operator works elementwise on boolean series (like `and` in core python).\n",
    "\n",
    "> *Hint 2*: copying of the dataframe is done with the `copy` method for DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Station identifier  Data  Observation value Observation type\n",
      "0          ITE00100550  TMAX                 10                E\n",
      "75         ITE00100550  TMAX                  8                E\n",
      "152        ITE00100550  TMAX                -28                E\n",
      "227        ITE00100550  TMAX                  0                E\n",
      "305        ITE00100550  TMAX                -19                E\n",
      "    Station identifier  Data  Observation value Observation type\n",
      "0          ITE00100550  TMAX                 10                E\n",
      "75         ITE00100550  TMAX                  8                E\n",
      "152        ITE00100550  TMAX                -28                E\n",
      "227        ITE00100550  TMAX                  0                E\n",
      "305        ITE00100550  TMAX                -19                E\n"
     ]
    }
   ],
   "source": [
    "# [Answer to Ex. 4.1.3]\n",
    "#print(df2['Station identifier'])\n",
    "df3 = df2[(df2['Station identifier']=='ITE00100550') & (df2['Data']=='TMAX')]\n",
    "#df3['Station identifier'] = 0\n",
    "print(df3.head(5))\n",
    "df4 = df3.copy()\n",
    "print(df4.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 4.1.4:** Make a new column called `TMAX_F` where you have converted the temperature variables to Fahrenheit. \n",
    "\n",
    "> *Hint*: Conversion is $F = 32 + 1.8*C$ where $F$ is Fahrenheit and $C$ is Celsius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Station identifier  Data  Observation value Observation type  TMAX_F\n",
      "0          ITE00100550  TMAX                 10                E    50.0\n",
      "75         ITE00100550  TMAX                  8                E    46.4\n",
      "152        ITE00100550  TMAX                -28                E   -18.4\n",
      "227        ITE00100550  TMAX                  0                E    32.0\n",
      "305        ITE00100550  TMAX                -19                E    -2.2\n"
     ]
    }
   ],
   "source": [
    "# [Answer to Ex. 4.1.4]\n",
    "df4['TMAX_F'] = 32+1.8*df4['Observation value']\n",
    "print(df4.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex 4.1.5:**  Inspect the indices, are they following the sequence of natural numbers, 0,1,2,...? If not, reset the index and make sure to drop the old."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Station identifier  Data  Observation value Observation type  TMAX_F\n",
      "0        ITE00100550  TMAX                 10                E    50.0\n",
      "1        ITE00100550  TMAX                  8                E    46.4\n",
      "2        ITE00100550  TMAX                -28                E   -18.4\n",
      "3        ITE00100550  TMAX                  0                E    32.0\n",
      "4        ITE00100550  TMAX                -19                E    -2.2\n"
     ]
    }
   ],
   "source": [
    "# [Answer to Ex. 4.1.5]\n",
    "df5 = df4.reset_index(drop = True)\n",
    "print(df5.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex 4.1.6:** Make a new DataFrame where you have sorted by the maximum temperature. What is the date for the first and last observations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Station identifier  Data  Observation value Observation type  TMAX_F\n",
      "221        ITE00100550  TMAX                348                E   658.4\n",
      "214        ITE00100550  TMAX                346                E   654.8\n",
      "220        ITE00100550  TMAX                341                E   645.8\n",
      "213        ITE00100550  TMAX                335                E   635.0\n",
      "217        ITE00100550  TMAX                335                E   635.0\n",
      "18641231\n",
      "18640101\n"
     ]
    }
   ],
   "source": [
    "# [Answer to Ex. 4.1.6]\n",
    "df6 = df5.sort_values('TMAX_F', ascending = False)\n",
    "print(df6.head(5))\n",
    "print(max(df[1]))\n",
    "print(min(df[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex 4.1.7:** CVS-files: save your DataFrame as a CSV file. what does index argument do?\n",
    "\n",
    "> Try to save the file using a relative path and an absolut path. \n",
    "With a relative you only specify the file name. This will save the file in the folder you are currently working in. With an absolute path, you specify the whole path, which allows you to save the file in a folder of your choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to Ex. 4.1.7]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> (Bonus) **Ex. 4.1.8**: A very compact way of writing code and making list in Python, is called list comprehensions. Depending on what you are doing, list can be more or less efficient that for example vectorized operations using NumPy. \n",
    "\n",
    ">Read about list comprehenseions online, and use it to make a list with the numbers from 0 to a million (10\\*\\*6), and add 3 to each element. Do the same doing NumPy, and time both methods. Which method is faster? \n",
    "\n",
    "> *Hint 1*: Use the `timeit` package for timing each method "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
