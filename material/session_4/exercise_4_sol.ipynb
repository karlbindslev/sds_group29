{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Set 4: Data Structuring 1\n",
    "\n",
    "*Afternoon, August 14, 2018*\n",
    "\n",
    "In this Exercise Set we will apply some of the basic things we have learned with pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load modules\n",
    "We begin by loading relevant packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Exercise Section 4.1: Weather, part 1\n",
    "\n",
    "Some data sources are open and easy to collect data from. They can be 'scraped' as is and they are already in a table format. This Exercise part of exercises is the first part of three that work with weather data, the follow ups are Exercise Sections 6.1 and 7.1. Our source will be National Oceanic and Atmospheric Administration (NOAA) which have a global data collection going back a couple of centuries. This collection is called Global Historical Climatology Network (GHCN). A description of GHCN can be found [here](https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/by_year/readme.txt)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> **Ex. 4.1.1:** Use Pandas' CSV reader to fetch  daily data weather from 1864 for various stations - available [here](https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/by_year/). \n",
    "\n",
    "> *Hint 1*: for compressed files you may need to specify the keyword `compression`.\n",
    "\n",
    "> *Hint 2*: keyword `header` can be specified as the CSV has no column names.\n",
    "\n",
    "> *Hint 3*: Specify the path, as the URL linking directly to the 1864 file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to Ex. 4.1.1]\n",
    "\n",
    "# Will be in assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> **Ex. 4.1.2:** Structure your weather DataFrame by using only the relevant columns (station identifier, data, observation type, observation value), rename them. Make sure observations are correctly formated (how many decimals should we add? one?).\n",
    "\n",
    "> *Hint:* rename can be done with `df.columns=COLS` where `COLS` is a list of column names.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to Ex. 4.1.2]\n",
    "\n",
    "# Will be in assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> **Ex. 4.1.3:**  Select data for the station `ITE00100550` and only observations for maximal temperature. Make a copy of the DataFrame. Explain in a one or two sentences how copying works.\n",
    "\n",
    "> *Hint 1*: the `&` operator works elementwise on boolean series (like `and` in core python).\n",
    "\n",
    "> *Hint 2*: copying of the dataframe is done with the `copy` method for DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to Ex. 4.1.3]\n",
    "\n",
    "# Will be in assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 4.1.4:** Make a new column called `TMAX_F` where you have converted the temperature variables to Fahrenheit. \n",
    "\n",
    "> *Hint*: Conversion is $F = 32 + 1.8*C$ where $F$ is Fahrenheit and $C$ is Celsius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to Ex. 4.1.4]\n",
    "\n",
    "# Will be in assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex 4.1.5:**  Inspect the indices, are they following the sequence of natural numbers, 0,1,2,...? If not, reset the index and make sure to drop the old."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to Ex. 4.1.5]\n",
    "\n",
    "df_select = df_select.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex 4.1.6:** Make a new DataFrame where you have sorted by the maximum temperature. What is the date for the first and last observations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min temp:  -6.3 Max temp:  34.8\n"
     ]
    }
   ],
   "source": [
    "# [Answer to Ex. 4.1.6]\n",
    "\n",
    "df_sorted = df_select.sort_values(by=['obs_value'])\n",
    "print(\"Min temp: \", df_sorted['obs_value'].iloc[0] , \"Max temp: \", df_sorted['obs_value'].iloc[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex 4.1.7:** CVS-files: save your DataFrame as a CSV file. what does index argument do?\n",
    "\n",
    "> Try to save the file using a relative path and an absolut path. \n",
    "With a relative you only specify the file name. This will save the file in the folder you are currently working in. With an absolute path, you specify the whole path, which allows you to save the file in a folder of your choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to Ex. 4.1.7]\n",
    "\n",
    "# Using relativ path\n",
    "df_sorted.to_csv('df_sorted.csv', index=False)\n",
    "# Using absolute path\n",
    "df_sorted.to_csv('C:/Users/rch690/Downloads/df_sorted.csv', index=False)\n",
    "# The index argument regulates whether or not the index is transfered to the CSV-file. Default is that it is transfered. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> (Bonus) **Ex. 4.1.8**: A very compact way of writing code and making list in Python, is called list comprehensions. Depending on what you are doing, list can be more or less efficient that for example vectorized operations using NumPy. \n",
    "\n",
    ">Read about list comprehenseions online, and use it to make a list with the numbers from 0 to a million (10\\*\\*6), and add 3 to each element. Do the same doing NumPy, and time both methods. Which method is faster? \n",
    "\n",
    "> *Hint 1*: Use the `timeit` package for timing each method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106 ms ± 14.4 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "[i+3 for i in range(10**6)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.14 ms ± 265 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "np.arange(10**6)+3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
